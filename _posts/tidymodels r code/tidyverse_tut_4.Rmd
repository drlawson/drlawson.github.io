---
title: "Tidymodels tutorial 4"
output: html_document
---

```{r}
library(tidymodels)

library(rpart.plot) #visualize a decision tree
library(vip) #for variable importance plots
```

going to use the cells data again (see tutorial 3)
```{r}
data(cells,package = "modeldata")

cells
```


Splitting the data into training and testing sets
```{r}
set.seed(123)
cell_split <- initial_split(cells %>% select(-case),
                            strata = class)
cell_train<- training(cell_split)
cell_test<- testing(cell_split)
```

Decision tree model
```{r}
tune_spec <-
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% set_engine("rpart") %>%
  set_mode("classification") #same as in tutorial 3

#tune here is thought of as a "placeholder," meaning that after the tuning process we will select a single numerical value for each of the parameters 

tune_spec
```



```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels=5) #this means we will have 5 values for each hyperparameter, meaning a grid of 5x5, or 25

tree_grid
```

Split data into folds
```{r}
set.seed(234)
cell_folds <- vfold_cv(cell_train) #creating folds from the cell training data - the default is 10 folds so if you do not plug in a value for v, it will automatically output 10 folds

cell_folds
```







```{r}
set.seed(345)

tree_wf <- workflow() %>%
  add_model(tune_spec) %>%
  add_formula(class ~ .) #this tells the model what the outcome is (class), and what the predictors are (the dot signifies that all other variables in the data will be treated as predictors)

tree_res <- 
  tree_wf %>%
  tune_grid(
    resamples = cell_folds, #this is the folds we created from our data
    grid = tree_grid #this is the grid with the 5 values for each hyperparameter to try with our model 
  )
```


```{r}
tree_res %>%
  collect_metrics()
```


GGplot visualization 
```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth))+
  geom_line(size=1.5, alpha = 0.6) +
  geom_point(size =2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```


```{r}
tree_res %>% 
  show_best("accuracy")
```

```{r}
best_tree <- tree_res %>%
  select_best("accuracy")

best_tree
```

Finalize our workflow
```{r}
final_wf <-
  tree_wf %>% #the workflow we had previously created
  finalize_workflow(best_tree)

final_wf
```


```{r}
final_fit <- 
  final_wf %>%
  last_fit(cell_split)

final_fit %>%
  collect_metrics() #gives us the accuracy and area under the roc curves for the final model 
```

```{r}
final_fit %>%
  collect_predictions() %>%
  roc_curve(class, .pred_PS) %>%
  autoplot()
```

```{r}
final_tree <- extract_workflow (final_fit)

final_tree
```

```{r}
final_tree %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE)
```

```{r}
final_tree %>%
  extract_fit_parsnip() %>%
  vip()
```



























trying with min_n!!

```{r}
library(tidymodels)

library(rpart.plot) 
library(vip) 
```

going to use the cells data again (see tutorial 3)
```{r}
data(cells,package = "modeldata")

cells
```


Splitting the data into training and testing sets
```{r}
set.seed(123)
cell_split <- initial_split(cells %>% select(-case),
                            strata = class)
cell_train<- training(cell_split)
cell_test<- testing(cell_split)
```

Decision tree model
```{r}
tune_spec <-
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()) %>% 
  set_engine("rpart") %>%
  set_mode("classification") #same as in tutorial 3

#tune here is thought of as a "placeholder," meaning that after the tuning process we will select a single numerical value for each of the parameters 

tune_spec
```

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(),
                          levels=5) #this means we will have 5 values for each hyperparameter, meaning a grid of 5x5, or 25

tree_grid
```

Split data into folds
```{r}
set.seed(234)
cell_folds <- vfold_cv(cell_train) #creating folds from the cell training data - the default is 10 folds so if you do not plug in a value for v, it will automatically output 10 folds

cell_folds
```

```{r}
set.seed(345)

tree_wf <- workflow() %>%
  add_model(tune_spec) %>%
  add_formula(class ~ .) #this tells the model what the outcome is (class), and what the predictors are (the dot signifies that all other variables in the data will be treated as predictors)

tree_res <- 
  tree_wf %>%
  tune_grid(
    resamples = cell_folds, #this is the folds we created from our data
    grid = tree_grid #this is the grid with the 5 values for each hyperparameter to try with our model 
  )
```


```{r}
tree_res %>%
  collect_metrics()
```


GGplot visualization 
```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth, shape = min_n))+
  geom_line(size=1.5, alpha = 0.6) +
  geom_point(size =2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```


```{r}
tree_res %>% 
  show_best("accuracy")
```

```{r}
best_tree <- tree_res %>%
  select_best("accuracy")

best_tree
```

Finalize our workflow
```{r}
final_wf <-
  tree_wf %>% #the workflow we had previously created
  finalize_workflow(best_tree)

final_wf
```


```{r}
final_fit <- 
  final_wf %>%
  last_fit(cell_split)

final_fit %>%
  collect_metrics() #gives us the accuracy and area under the roc curves for the final model 
```
